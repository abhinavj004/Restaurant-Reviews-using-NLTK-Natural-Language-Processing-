{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Restaurant_Reviews.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ot0nuTqY7Xl2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Description of the dataset to be used:\n",
        "\n",
        "* Columns seperated by \\t (tab space)\n",
        "* First column is about reviews of people\n",
        "* In second column, 0 is for negative review and 1 is for positive review"
      ]
    },
    {
      "metadata": {
        "id": "YU9XKxiZl4vO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Step 1 :- **\n",
        "Import dataset with setting delimiter as ‘\\t’ as columns are separated as tab space. "
      ]
    },
    {
      "metadata": {
        "id": "dl3Pj_mVBqlL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iKz-CfnbBqyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "020f998f-bb2d-49a1-9b54-9711b8095a49"
      },
      "cell_type": "code",
      "source": [
        "! ls  \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Restaurant_Reviews (1).tsv'   Restaurant_Reviews.tsv   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "avO6UiG-Bq0V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t' , quoting = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_NfrfFkBq6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1882
        },
        "outputId": "925c16ca-0893-4ed0-c4e0-955b604a8db8"
      },
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Now I am getting angry and I want my damn pho.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The potatoes were like rubber and you could te...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The fries were great too.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A great touch.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Service was very prompt.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Would not go back.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>The cashier had no care what so ever on what I...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>I tried the Cape Cod ravoli, chicken, with cra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I was disgusted because I was pretty sure that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I was shocked because no signs indicate cash o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Highly recommended.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Waitress was a little slow in service.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>This place is not worth your time, let alone V...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>did not like at all.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>The Burrittos Blah!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The food, amazing.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Service is also cute.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>I could care less... The interior is just beau...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>So they performed.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>That's right....the red velvet cake.....ohhh t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>- They never brought a salad we asked for.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>This hole in the wall has great Mexican street...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Took an hour to get our food only 4 tables in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>The worst was the salmon sashimi.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>I immediately said I wanted to talk to the man...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>The ambiance isn't much better.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>Unfortunately, it only set us up for disapppoi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>The food wasn't good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>974</th>\n",
              "      <td>Your servers suck, wait, correction, our serve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>975</th>\n",
              "      <td>What happened next was pretty....off putting.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>976</th>\n",
              "      <td>too bad cause I know it's family owned, I real...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>Overpriced for what you are getting.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>I vomited in the bathroom mid lunch.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>I kept looking at the time and it had soon bec...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>I have been to very few places to eat that und...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>We started with the tuna sashimi which was bro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>Food was below average.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>It sure does beat the nachos at the movies but...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>All in all, Ha Long Bay was a bit of a flop.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>The problem I have is that they charge $11.99 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>986</th>\n",
              "      <td>Shrimp- When I unwrapped it (I live only 1/2 a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>987</th>\n",
              "      <td>It lacked flavor, seemed undercooked, and dry.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>It really is impressive that the place hasn't ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>I would avoid this place if you are staying in...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>990</th>\n",
              "      <td>The refried beans that came with my meal were ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>Spend your money and time some place else.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>A lady at the table next to us found a live gr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>the presentation of the food was awful.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>I can't tell you how disappointed I was.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>I think food should have flavor and texture an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Appetite instantly gone.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Overall I was not impressed and would not go b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>The whole experience was underwhelming, and I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Review  Liked\n",
              "0                             Wow... Loved this place.      1\n",
              "1                                   Crust is not good.      0\n",
              "2            Not tasty and the texture was just nasty.      0\n",
              "3    Stopped by during the late May bank holiday of...      1\n",
              "4    The selection on the menu was great and so wer...      1\n",
              "5       Now I am getting angry and I want my damn pho.      0\n",
              "6                Honeslty it didn't taste THAT fresh.)      0\n",
              "7    The potatoes were like rubber and you could te...      0\n",
              "8                            The fries were great too.      1\n",
              "9                                       A great touch.      1\n",
              "10                            Service was very prompt.      1\n",
              "11                                  Would not go back.      0\n",
              "12   The cashier had no care what so ever on what I...      0\n",
              "13   I tried the Cape Cod ravoli, chicken, with cra...      1\n",
              "14   I was disgusted because I was pretty sure that...      0\n",
              "15   I was shocked because no signs indicate cash o...      0\n",
              "16                                 Highly recommended.      1\n",
              "17              Waitress was a little slow in service.      0\n",
              "18   This place is not worth your time, let alone V...      0\n",
              "19                                did not like at all.      0\n",
              "20                                 The Burrittos Blah!      0\n",
              "21                                  The food, amazing.      1\n",
              "22                               Service is also cute.      1\n",
              "23   I could care less... The interior is just beau...      1\n",
              "24                                  So they performed.      1\n",
              "25   That's right....the red velvet cake.....ohhh t...      1\n",
              "26          - They never brought a salad we asked for.      0\n",
              "27   This hole in the wall has great Mexican street...      1\n",
              "28   Took an hour to get our food only 4 tables in ...      0\n",
              "29                   The worst was the salmon sashimi.      0\n",
              "..                                                 ...    ...\n",
              "970  I immediately said I wanted to talk to the man...      0\n",
              "971                    The ambiance isn't much better.      0\n",
              "972  Unfortunately, it only set us up for disapppoi...      0\n",
              "973                              The food wasn't good.      0\n",
              "974  Your servers suck, wait, correction, our serve...      0\n",
              "975      What happened next was pretty....off putting.      0\n",
              "976  too bad cause I know it's family owned, I real...      0\n",
              "977               Overpriced for what you are getting.      0\n",
              "978               I vomited in the bathroom mid lunch.      0\n",
              "979  I kept looking at the time and it had soon bec...      0\n",
              "980  I have been to very few places to eat that und...      0\n",
              "981  We started with the tuna sashimi which was bro...      0\n",
              "982                            Food was below average.      0\n",
              "983  It sure does beat the nachos at the movies but...      0\n",
              "984       All in all, Ha Long Bay was a bit of a flop.      0\n",
              "985  The problem I have is that they charge $11.99 ...      0\n",
              "986  Shrimp- When I unwrapped it (I live only 1/2 a...      0\n",
              "987     It lacked flavor, seemed undercooked, and dry.      0\n",
              "988  It really is impressive that the place hasn't ...      0\n",
              "989  I would avoid this place if you are staying in...      0\n",
              "990  The refried beans that came with my meal were ...      0\n",
              "991         Spend your money and time some place else.      0\n",
              "992  A lady at the table next to us found a live gr...      0\n",
              "993            the presentation of the food was awful.      0\n",
              "994           I can't tell you how disappointed I was.      0\n",
              "995  I think food should have flavor and texture an...      0\n",
              "996                           Appetite instantly gone.      0\n",
              "997  Overall I was not impressed and would not go b...      0\n",
              "998  The whole experience was underwhelming, and I ...      0\n",
              "999  Then, as if I hadn't wasted enough of my life ...      0\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "VzduSS9bglKo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Step 2  :-\n",
        "\n",
        "**Cleaning the text**"
      ]
    },
    {
      "metadata": {
        "id": "oPbXipb4gqsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9975d775-ed5e-4520-b269-4726d82c536b"
      },
      "cell_type": "code",
      "source": [
        "# library to clean data \n",
        "import re  \n",
        "  \n",
        "# Natural Language Tool Kit \n",
        "import nltk  \n",
        "  \n",
        "nltk.download('stopwords') \n",
        "  \n",
        "# to remove stopword \n",
        "from nltk.corpus import stopwords \n",
        "  \n",
        "# for Stemming propose  \n",
        "from nltk.stem.porter import PorterStemmer \n",
        "  \n",
        "# Initialize empty array \n",
        "# to append clean text  \n",
        "corpus = []  \n",
        "  \n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SW6NHPgRoAaz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocessing The Text\n",
        "\n",
        "\n",
        "\n",
        "*  **Remove Punctuations, Numbers :**  Punctuations, Numbers doesn’t help much in processong the given text, if included, they will just increase the size of bag of words that we will create as last step and decrase the efficency of algorithm.\n",
        "\n",
        "*   **Stemming :** Take roots of the word\n",
        "\n",
        "*   **Convert each word into root case :** For example, it useless to have same words in different cases (eg ‘good’ and ‘GOOD’).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2mo8uUE7Bq_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 1000 (reviews) rows to clean \n",
        "for i in range(0, 1000):  \n",
        "      \n",
        "    # column : \"Review\", row ith \n",
        "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])  \n",
        "      \n",
        "    # convert all cases to lower cases \n",
        "    review = review.lower()  \n",
        "      \n",
        "    # split to array(default delimiter is \" \") \n",
        "    review = review.split()  \n",
        "      \n",
        "    # creating PorterStemmer object to \n",
        "    # take main stem of each word \n",
        "    ps = PorterStemmer()  \n",
        "      \n",
        "    # loop for stemming each word \n",
        "    # in string array at ith row     \n",
        "    review = [ps.stem(word) for word in review \n",
        "                if not word in set(stopwords.words('english'))]  \n",
        "                  \n",
        "    # rejoin all string array elements \n",
        "    # to create back into a string \n",
        "    review = ' '.join(review)   \n",
        "      \n",
        "    # append each string to create \n",
        "    # array of clean text  \n",
        "    corpus.append(review)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2-OO2eMpgp8o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating the Bag of Words model \n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "  \n",
        "# To extract max 1500 feature. \n",
        "# \"max_features\" is attribute to \n",
        "# experiment with to get better results \n",
        "cv = CountVectorizer(max_features = 1500)  \n",
        "  \n",
        "# X contains corpus (dependent variable) \n",
        "X = cv.fit_transform(corpus).toarray()  \n",
        "  \n",
        "# y contains answers if review \n",
        "# is positive or negative \n",
        "y = dataset.iloc[:, 1].values "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CFmgc9eaBrBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e584b64d-b88f-4697-a42c-3a8062ea989b"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ur0MyxLYBrFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "fa28f145-ec6f-4305-edcb-47e609ad0d95"
      },
      "cell_type": "code",
      "source": [
        "review = review.split()\n",
        "review = [word for word in review if not word in set(stopwords.words('english'))]\n",
        "review"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wast',\n",
              " 'enough',\n",
              " 'life',\n",
              " 'pour',\n",
              " 'salt',\n",
              " 'wound',\n",
              " 'draw',\n",
              " 'time',\n",
              " 'took',\n",
              " 'bring',\n",
              " 'check']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "zl3nM4L3BrHb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus = []\n",
        "for i in range(0, 1000):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    ps = PorterStemmer()\n",
        "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dwB9VvVyo9gK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Step 4: Making the bag of words via sparse matrix\n",
        "\n",
        "*  Take all the different words of reviews in the dataset without repeating of words.\n",
        "*  One column for each word, therefore there are going to be many columns.\n",
        "*  Rows are reviews\n",
        "*  If word is there in row of dataset of reviews, then the count of word will be there in row of bag of words under the column of the word."
      ]
    },
    {
      "metadata": {
        "id": "bhrJIz9VBrK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating the Bag of Words model \n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "  \n",
        "# To extract max 1500 feature. \n",
        "# \"max_features\" is attribute to \n",
        "# experiment with to get better results \n",
        "cv = CountVectorizer(max_features = 1500)  \n",
        "  \n",
        "# X contains corpus (dependent variable) \n",
        "X = cv.fit_transform(corpus).toarray()  \n",
        "  \n",
        "# y contains answers if review \n",
        "# is positive or negative \n",
        "y = dataset.iloc[:, 1].values  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R-KIv_P05D0o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Step 5 :-\n",
        "* Splitting Corpus into Training and Test set."
      ]
    },
    {
      "metadata": {
        "id": "tf1J3zrRMM6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "70cb6ca9-ddf7-4ae7-8130-b53f809bb6eb"
      },
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.cross_validation import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kOsR5-o05b7l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Step 6:-\n",
        "*  Fitting a Predictive Model (here random forest)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "MYKEiyGRMM9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44c263a8-9094-47e2-e3c1-44bc785272e8"
      },
      "cell_type": "code",
      "source": [
        "# Fitting Naive Bayes to the Training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "8v0T2UxgMNAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "8ebadb85-ea02-45a0-c77b-36f642348b92"
      },
      "cell_type": "code",
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "Xcq-dYZ2MpLc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "17X6J3_eMpOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "20711328-56df-4b8d-bbda-75892380904c"
      },
      "cell_type": "code",
      "source": [
        "cm"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[55, 42],\n",
              "       [12, 91]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "7dZ2uwIjMpWr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}